\documentclass[nojss]{jss}
\usepackage{float}
\usepackage{graphicx}
\usepackage{amsmath}

%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN Custom Commands %
%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\Sref}[1]{Section~\ref{#1}}  
\newcommand{\argmin}{\operatornamewithlimits{arg\,min\ }}  
\newcommand{\argmax}{\operatornamewithlimits{arg\,max\ }}  
\newcommand{\mean}{\text{mean}}    
\newtheorem{claim}{Claim}

%%%%%%%%%%%%%%%%%%%%%%%
% END Custom Commands %
%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%
% BEGIN TikZ Commands %
%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usetikzlibrary{shapes, arrows}
\usepackage{amsmath}
\usepackage{xspace}
\newcommand{\A}{\ensuremath{\mathcal{A}}\xspace}
\newcommand{\B}{\ensuremath{\mathcal{B}}\xspace}
\newcommand\pa[1]{\ensuremath{\left(#1\right)}}

%%%%%%%%%%%%%%%%%%%%%
% END TikZ Commands %
%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Gary King\\Harvard University \And 
        Christopher Lucas\\Harvard University \And 
        Richard Nielsen\\MIT}
\title{\pkg{MatchingFrontier}: \proglang{R} Package for Computing the Matching Frontier\thanks{The current release of \pkg{MatchingFrontier} is in active development and will continue to grow over the coming months. Comments and suggestions are greatly appreciated.}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Gary King, Christopher Lucas, Richard Nielsen} %% comma-separated
\Plaintitle{MatchingFrontier: R Package for Computing the Matching Frontier} %% without formatting
\Shorttitle{\pkg{MatchingFrontier}} %%  short title (if necessary)

%% an abstract and keywords
\Abstract{ \pkg{MatchingFrontier} is an \proglang{R} package that
  implements the methods described in \citet{kingND} for optimizing
  both balance and sample size in matching methods for causal
  inference. \pkg{MatchingFrontier} supports the computation of
  frontiers for both continuous and discrete metrics and also provides
  functions for visualizing the frontier and exporting matched data
  sets for further analysis.}

\Keywords{\proglang{R}, matching, frontier, Mahalanobis, L1}
\Plainkeywords{R, matching, frontier, Mahalanobis, L1} %% without formatting
\Address{
  Gary King\\
  Department of Government\\
  Harvard University\\
  1737 Cambridge St, Cambridge, MA, USA\\
  E-mail: \href{mailto:king@harvard.edu}{king@harvard.edu}\\
  URL: \href{http://gking.harvard.edu/}{http://gking.harvard.edu/}\\

  Christopher Lucas\\
  Department of Government\\
  Harvard University\\
  1737 Cambridge St, Cambridge, MA, USA\\
  E-mail: \href{mailto:clucas@fas.harvard.edu}{clucas@fas.harvard.edu}\\
  URL: \href{http://christopherlucas.org/}{christopherlucas.org}\\

  Richard Nielsen\\
  Department of Political Science\\
  Massachusetts Institute of Technology\\
  77 Massachusetts Avenue, Cambridge, MA, USA\\
  E-mail: \href{mailto:rnielsen@mit.edu}{rnielsen@mit.edu}\\
  URL: \href{http://www.mit.edu/~rnielsen/index.htm}{http://www.mit.edu/~rnielsen/index.htm}

}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.

\section[Introduction]{Introduction}

Matching methods have become extremely popular amongst researchers
working with observational data, especially when used as a
nonparametric preprocessing step to reduce model dependence
\citep{ho2007,ho2009}. But despite this popularily, existing matching
approaches leave researchers with two fundamental tensions. First,
they are designed to maximize one metric (such as propensity score or
Mahalanobis distance) but are judged against another for which they
were not designed (such as $L1$ or differences in means). Second, they
lack a principled solution to revealing the implicit bias-variance
trade off: matching methods need to optimize with respect to both
imbalance (between the treated and control groups) and the number of
observations pruned, but existing approaches optimize with respect to
only one; users then either ignore the second or tweak it without a
formal stopping rule.

\pkg{MatchingFrontier} resolves both tensions by consolidating
previous techniques into a single, optimal, and flexible approach. The
software calculates the matching solution with maximum balance for
each possible sample size $(N, N-1, N-2,...)$ and returns each
solution, the whole of which constitute the \emph{frontier}, from
which the user can easily choose one, several, or all subsamples with
which to conduct the final analysis, given their own choice of
imbalance metric and quantity of interest. \pkg{MatchingFrontier}
solves the joint optimization problem in one run, automatically,
without manual tweaking, and without iteration.  Although for each
subset size $k$, there exist a huge number of unique subsets $N
\choose k$, \pkg{MatchingFrontier} includes specially designed and
extremely fast algorithms that give the optimal answer, usually in a
few minutes or less.

\section[What MatchingFrontier Does]{General Framework}\label{sec:framework}

Matching methods are designed to reduce imbalance in data by
selectively pruning observations, which in turn reduces model
dependence \citep{king2006,imai2008,iacus2011a,ho2007}. However,
pruning reduces sample size and therefore may increase variance in the
eventual estimates. Users of matching are then confronted with the
perennial bias-variance trade-off. Perhaps surprisingly, existing
approaches to matching do not conduct the implied joint optimization
of bias and variance. Rather, they improve one dimension of the
optimization and leave the second to the user. Such an approach is
time consuming and rarely yields the optimal solution.

\citet{kingND} proposes a solution to this joint optimization, which
is implemented in \pkg{MatchingFrontier}. Discrete and continuous
metrics are defined and algorithms are provided for both continuous
and discrete metrics, thus rendering the method agnostic to the
metric. We point users of \pkg{MatchingFrontier} to \citet{kingND} for
algorithmic details and theoretical proofs. In this section, we
provide definitions of the metrics so that users can choose
appropriately when using \code{makeFrontier()}.

For discrete metrics, we follow \citep{iacus2011b} and use the
difference between the multivariate histograms of the treated and
control groups. Formally, let $f_{\ell_1\cdots \ell_k}$ be the
relative empirical frequency of treated units in a bin with
coordinates on each of the $X$ variables as $\ell_1\cdots \ell_k$ so
that $f_{\ell_1\cdots \ell_k}=n_{T_{\ell_1\cdots \ell_k}}/n_T$ where
$n_{T_{\ell_1\cdots \ell_k}}$ is the number of treated units in
stratum $\ell_1\cdots \ell_k$ and $n_T$ is the number of treated units
in all strata. We define $g_{\ell_1\cdots \ell_k}$ similarly among
control units. Then:
\begin{equation}\label{eq:L1} 
  L_1(H) =\frac{1}{2} \sum_{(\ell_1
    \cdots \ell_k) \in H} |f_{\ell_1\cdots \ell_k} - g_{\ell_1\cdots
    \ell_k}| 
\end{equation} 

For continuous metrics, we define the Average Mahalanobis Imbalance
(AMI). Though easily generalized to all continuous measures of
distance, we choose Mahalanobis distance. AMI is the distance between
each unit $i$ and the closest unit in the opposite group, averaged
over all units: $D=\mean_i [D(X_i,X_{j(i)})]$, where the closest unit
in the opposite group is
$X_{j(i)}=\argmin_{X_j|j\in\{1-T_i\}}[D(X_i,X_j)]$ and $\{1-T_i\}$ is
the set of units in the (treatment or control) group that does not
contain $i$. \pkg{MatchingFrontier} defaults to AMI but can just as
easily be used with $L_1$.

Of note is that these metrics presume a dichotomous treatment.  Given
recent advances in matching with continuous treatments \citep{iacusND,
  ratkovicND}, we encourage researchers to consider generalizing our
algorithms (and therefore, metrics) to continuous treatment regimes.

\section[Getting Started]{Getting Started}

\pkg{MatchingFrontier} is written in the \proglang{R} language
\citep{r2012} and is currently hosted on Github and CRAN. CRAN hosts
the latest stable release. You can install the current development
release of \pkg{MatchingFrontier} with the \pkg{devtools} package
\citep{wickham2013}, as follows.

\begin{Code}
> library(devtools) 
> install_github('ChristopherLucas/MatchingFrontier/package')
\end{Code} 

Alternatively, you can install the development version of
\pkg{MatchingFrontier} from a *nix command line as follows.

\begin{Code}
$ curl -OL https://github.com/ChristopherLucas/MatchingFrontier/archive/master.zip
$ unzip master.zip
$ cd MatchingFrontier-master
$ R CMD INSTALL package
\end{Code} 

\section[A User's Guide]{A User's Guide}

The typical \pkg{MatchingFrontier} workflow is displayed in
Figure~\ref{fig:workflow}. Note that in nearly all cases, users first
proceed through the two-step process of computing the frontier and
then estimating quantities of interest across it. After these steps
are completed, the results can be used to visually summarize the full
frontier or to closely inspect a particular point on it.  Next, we
illustrate this workflow with the LaLonde data
\citep{lalonde1986,dehejia1999}, which is included in
\pkg{MatchingFrontier}.


\begin{figure}[H]
\centering
\begin{tikzpicture}[
    grow = down,
    ->,thick,
    sibling distance=6cm,
    level 1/.style={sibling distance=6cm, level distance = 1.5cm},
    level 2/.style={sibling distance=5cm, level distance = 3cm}, 
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    make/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=white!80!black!20, draw=black, 
    semithick,text width = 3cm,align = center},
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    estimate/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=white!80!black!20, draw=black, 
    semithick,text width = 4cm,align = center},
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    export/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=white!80!black!20, draw=black, 
    semithick,text width = 3.5cm,align = left},
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    plotting/.style={rectangle, rounded corners, shade, top color=white,
    bottom color=white!80!black!20, draw=black, 
    semithick,text width = 3cm,align = left},
    ]
    \tikzstyle{every node}=[circle,draw]
    \node[make]{\code{makeFrontier()}}
        child { 
            node[estimate] {\code{estimateEffects()}}
            child { node[plotting] {\code{plotFrontier()} 
                                    \code{plotEstimates()} 
                                    \code{plotMeans()}} 
              edge from parent node[left,draw=none]{Visualize the full frontier} 
            }
            child { node[export]{\code{generateDataset()} 
                                 \code{parallelPlot()}} 
              edge from parent node[right,draw=none]{Analyze a single frontier point}}
        }
          ;
\end{tikzpicture}
\caption{A typical \pkg{MatchingFrontier}
  workflow. \code{makeFrontier()} is used to construct the frontier,
  then \code{estimateEffects()} is used to estimate quantities of
  interest for each point on the frontier, after which the user may
  proceed to visualize the full frontier or to inspect individual
  points on it.}\label{fig:workflow}
\end{figure}

\subsection{LaLonde Example}

For the running example in this paper, we the ``LaLonde'' data
\citep{lalonde1986, dehejia1999}\footnote{For a complete description
  of the data, type \code{?lalonde} after loading
  \pkg{MatchingFrontier}.}. The LaLonde data is commonly used to
assess matching methods and refers to the combination of data from an
experimental intervention containing 185 treated units (the National
Supported Work Demonstration) to observational data. By combining the
experimental data with observational data, methods can be compared to
the underlying experimental benchmark. We follow \citet{lalonde1986}
and combine the results of the experimental intervention with the
Current Population Survey. When combined, there are a total of 16,437
observations.

The LaLonde data contains a treatment indicator ``treat'' (an
indicator for assigment to a jobs training program), an outcome
measure ``re78'' (income in 1978), and a number of controls (potential
confounders) that we will match on during the illustration. The
controls are as follows.

\begin{itemize}
  \item[\textbf{age}:] subject age at time of intervention
  \item[\textbf{education}:] years of education
  \item[\textbf{black}:] a race indicator for identification as black
  \item[\textbf{hispanic}:] an ethnicity indicator for identification as hispanic
  \item[\textbf{married}:] an indicator for whether or not the subject is married
  \item[\textbf{nodegree}:] an indicator for whether or not the subject has a college degree
  \item[\textbf{re74}:] income in 1974
  \item[\textbf{re75}:] income in 1975
\end{itemize}

\subsection{Computing the Frontier}

The user must first create the frontier. To do so, use the
\code{makeFrontier()} function, which will calculate the optimal
subsample at every point on the frontier. By default,
\code{makeFrontier()} calculates the frontier with the Average
Mahalanobis Imbalance. However, as we demonstrate,
\pkg{MatchingFrontier} works just as easily with $L_1$ difference.

First, calculate the Mahalanobis frontier for the LaLonde
data.

\begin{CodeChunk}
\begin{CodeInput}
# Load the package and the data
> library(MatchingFrontier)
> data('lalonde')

# Create a vector of column names to indicate which variables we 
# want to match on. We will match on everything except the treatment
# and the outcome.
> match.on <- colnames(lalonde)[!(colnames(lalonde) %in% c('re78', 'treat'))]
> match.on # Print variables in match.on
[1] "age"       "education" "black"     "hispanic"  "married"   "nodegree" 
[7] "re74"      "re75"     
# Make the mahalanobis frontier
mahal.frontier <- makeFrontier(dataset = lalonde, 
                            treatment = 'treat', 
                            outcome = 're78', 
                            match.on = match.on)
Calculating Mahalanobis distances...
Calculating theoretical frontier...
Calculating information for plotting the frontier...
> mahal.frontier
An imbalance frontier with 13494 points.
\end{CodeInput}
\end{CodeChunk}

As shown above, \code{match.on} is a vector holding the variable names
that the user wishes to match on. Because \code{re78} is
the outcome and \code{treat} is the treatment, we exclude those
variable names from the vector.

By default, \code{makeFrontier()} calculates the frontier for the
Average Mahalanobis Imbalance, as defined in
Section~\ref{sec:framework}.  The default quantity of interest is the
\emph{feasible sample average treatment effect on the treated} or
FSATT \citep{kingND}, for which weights are calculated and returned to the
user. 

To instead calculate the $L_1$ frontier, simply
provide optional ``metric'', ``QOI'', and ``ratio'' arguments, as
follows.\footnote{For technical explanations of these arguments, we
  point users to \citet{kingND}.}

\begin{CodeChunk}
\begin{CodeInput}
# Make the L1 frontier
L1.frontier <- makeFrontier(dataset = lalonde, 
                            treatment = 'treat', 
                            outcome = 're78', 
                            match.on = match.on,
                            QOI = 'SATT',
                            metric = 'L1',
                            ratio = 'fixed')
Calculating L1 binnings...
Calculating L1 frontier... This may take a few minutes...
> L1.frontier
An imbalance frontier with 16170 points.
\end{CodeInput}
\end{CodeChunk}

Next, we will use the results computed above to estimate causal
effects along the frontier.

\subsection{Estimating Effects}

Continuing with the Lalonde example, we will estimate the effects
along the frontier with the \code{estimateEffects()} function, which
takes the output from \code{makeFrontier()} to estimate the effect of
the treatment along all values of the frontier. With the Lalonde
example, the code is as follows.

\begin{CodeChunk}
\begin{CodeInput}
# Estimate effects for the mahalanobis frontier
> mahal.estimates <- estimateEffects(mahal.frontier, 're78 ~ treat')

# Estimate effects for the L1 frontier
> L1.estimates <- estimateEffects(L1.frontier, 're78 ~ treat')
\end{CodeInput}
\end{CodeChunk}

\code{estimateEffects()} takes two arguments. The first argument is
the output from \code{makeFrontier()} and the second is the formula
passed to the \code{lm()} function. \code{estimateEffects} stores the
estimates and the 95\% confidence interval for each point it
estimates.

Alternatively, we could also condition on the variables that we are
matching on (stored in \code{match.on}) by specifying a different
formula, as follows.

\begin{CodeChunk}
\begin{CodeInput}
# Estimate effects for the mahalanobis frontier
> mahal.estimates.controls <- 
        estimateEffects(mahal.frontier, paste('re78 ~ treat +', 
                                        paste(match.on, collapse = ' + ')))

# Estimate effects for the L1 frontier
> L1.estimates.controls <- 
     estimateEffects(L1.frontier, paste('re78 ~ treat +', 
                                  paste(match.on, collapse = ' + ')))
\end{CodeInput}
\end{CodeChunk}

We've now estimated effects along the full frontier for AMI with and
without controls and for $L_1$ with and without controls. Next, we
will visually inspect the full frontier.

\subsection{Plotting the Frontier}

We can plot the frontier and the estimates with the plotting
functions, as follows. Note that for the sake of brevity, we will only
do so with the AMI frontier (no controls). However, to plot the other
three frontiers calculated in the previous section, simply pass the
corresponding objects to the plotting functions, as the syntax is the
same.

First, we will plot the frontier, where the $y$-axis is AMI and the
$x$-axis is the number of observations pruned. This is displayed in
Figure~\ref{fig:mahal_frontier_plain} next to the code that generated
it.

\begin{minipage}{0.45\textwidth}
\begin{CodeChunk}
\begin{CodeInput}
# Plot frontier
plotFrontier(mahal.frontier)
\end{CodeInput}
\end{CodeChunk}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{figure}[H]
\includegraphics{mahal_frontier_plain.pdf}
\caption{\label{fig:mahal_frontier_plain} The AMI frontier without optional arguments}
\end{figure}
\end{minipage} \hfill
\newline
\newline

However, Figure~\ref{fig:mahal_frontier_plain} is not especially
attractive.  The font is too small and the dots constituting the
frontier run into each other and create an ugly, fat line. All of the
plotting functions in \pkg{MatchingFrontier} use \proglang{R}'s
ellipsis feature to permit access to the base plotting
functionality. Figure~\ref{fig:mahal_frontier_pretty} shows an
example, along with the corresponding code.

\begin{minipage}{0.45\textwidth}
\begin{CodeChunk}
\begin{CodeInput}
# Plot frontier
plotFrontier(mahal.frontier,
             cex.lab = 1.4,
             cex.axis = 1.4,
             type = 'l',
             panel.first = 
                grid(NULL, 
                     NULL, 
                     lwd = 2)
             )
\end{CodeInput}
\end{CodeChunk}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{figure}[H]
\includegraphics{mahal_frontier_pretty.pdf}
\caption{\label{fig:mahal_frontier_pretty} The AMI frontier with optional arguments}
\end{figure}
\end{minipage} \hfill
\newline
\newline

\subsection{Plotting Estimates}

Next, we can plot estimates along the frontier. As in the previous
section, we will use the AMI frontier without controls. To do so,
we'll use the results from \code{makeFrontier()} and
\code{frontierEst()}. Figure~\ref{fig:mahal_frontier_est} displays these
results.

\begin{minipage}{0.45\textwidth}
\begin{CodeChunk}
\begin{CodeInput}
# Plot estimates
plotEstimates(mahal.estimates, 
              cex.lab = 1.4,
              cex.axis = 1.4,
              type = 'l',
              panel.first = 
                 grid(NULL,
                      NULL,
                      lwd = 2,
                      )
              )
\end{CodeInput}
\end{CodeChunk}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{figure}[H]
\includegraphics{mahal_frontier_est.pdf}
\caption{\label{fig:mahal_frontier_est} Estimates across the AMI frontier.}
\end{figure}
\end{minipage} \hfill
\newline
\newline

\subsection{Inspect a Single Point on the Frontier}

Lastly, users may wish to export a data set on the frontier for
additional analysis. To do so, users are likely to rely on
\code{parallelPlot()} and \code{generateDataset()}. Parellel plot
allows the user to visually inspect multiple dimensions of a data set
and requires only the output of \code{makeFrontier()}. For
illustration, we will create a parallel plot that displays 
the treated and control values on 'age', 're74', 're75', and
'black' for the point on the frontier where 13,000 observations
have been dropped. We will color treated units \textcolor{gray}{gray}
and control units \textcolor{blue}{blue}.

\begin{minipage}{0.45\textwidth}
\begin{CodeChunk}
\begin{CodeInput}
# Make parallel plot
parallelPlot(mahal.frontier,
             N = 13000,
             variables = c('age',
             're74',
             're75',
             'black'),
             treated.col = 'grey',
             control.col = 'blue'
             )
\end{CodeInput}
\end{CodeChunk}
\end{minipage}
\begin{minipage}{0.5\textwidth}
\begin{figure}[H]
\includegraphics{mahal_parplot.pdf}
\caption{\label{fig:mahal_parplot} Parallel plot for pruning 13,000 observations.}
\end{figure}
\end{minipage} \hfill
\newline
\newline

Figure \ref{fig:mahal_parplot} makes obvious the fact that there are many more control than 
treated units and that the sample still contains a large number of controls that are
not good matches for treated units, at least on these dimensions. Though this implies that
perhaps we might move even further down the frontier, for illustration, let's now export
this data set, using \code{generateDataset()} as follows.

\begin{CodeChunk}
\begin{CodeInput}
n <- 13000 # Identify the point from which to select the data
matched.data <- generateDataset(mahal.frontier, N = n)
\end{CodeInput}
\end{CodeChunk}

If the estimand is variable ratio, as it is by default, the exported
data set will include the appropriate weights necessary for estimating
the FSATT. We can now run a few simple regressions, controlling for
the variables we matched on, using the matched data.


\begin{table}[H] \centering 
  \caption{} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline \\[-1.8ex] 
\\[-1.8ex] & \multicolumn{2}{c}{re78} \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 treat & 1,173.718$^{***}$ & 1,529.322$^{***}$ \\ 
  & (239.164) & (233.791) \\ 
  age &  & $-$9.336 \\ 
  &  & (16.027) \\ 
  education &  & 470.740$^{***}$ \\ 
  &  & (81.595) \\ 
  black &  & $-$952.468$^{**}$ \\ 
  &  & (393.756) \\ 
  hispanic &  & $-$153.839 \\ 
  &  & (606.819) \\ 
  married &  & 365.978 \\ 
  &  & (324.197) \\ 
  nodegree &  & 233.513 \\ 
  &  & (365.707) \\ 
  re74 &  & $-$0.030 \\ 
  &  & (0.041) \\ 
  re75 &  & 0.506$^{***}$ \\ 
  &  & (0.055) \\ 
  Constant & 5,045.315$^{***}$ & 41.577 \\ 
  & (169.115) & (1,237.995) \\ 
 N & 3,437 & 3,437 \\ 
R$^{2}$ & 0.007 & 0.069 \\ 
Adjusted R$^{2}$ & 0.007 & 0.067 \\ 
Residual Std. Error & 2,268.912 (df = 3435) & 2,199.123 (df = 3427) \\ 
F Statistic & 24.084$^{***}$ (df = 1; 3435) & 28.346$^{***}$ (df = 9; 3427) \\ 
\hline \\[-1.8ex] 
\multicolumn{3}{l}{$^{*}$p $<$ .1; $^{**}$p $<$ .05; $^{***}$p $<$ .01} \\ 
\end{tabular} 
\end{table} 


\section[Conclusion]{Conclusion}

We demonstrated how to use the new \proglang{R} software package
\pkg{MatchingFrontier} for causal inference with observational data. With the
LaLonde data, users were shown how to compute the balance-sample size frontier,
calculate estimates along it, and visualize and inspect the results. 

\bibliography{bibliography}
\end{document}
